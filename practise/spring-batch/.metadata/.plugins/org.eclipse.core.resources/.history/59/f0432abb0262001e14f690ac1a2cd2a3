package com.coderelated.dbTOCSVTOawss3.config;

import java.util.List;

import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.StepScope;
import org.springframework.batch.core.configuration.support.DefaultBatchConfiguration;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.batch.item.data.RepositoryItemReader;
import org.springframework.batch.item.database.JpaPagingItemReader;
import org.springframework.batch.item.file.FlatFileItemWriter;
import org.springframework.batch.item.file.builder.FlatFileItemWriterBuilder;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.FileSystemResource;
import org.springframework.transaction.PlatformTransactionManager;

import com.coderelated.dbTOCSVTOawss3.model.Users;

import jakarta.persistence.EntityManagerFactory;
import software.amazon.awssdk.services.s3.S3Client;

@Configuration
@EnableBatchProcessing
public class BatchConfig extends DefaultBatchConfiguration{

//    @Autowired
//    private JobBuilderFactory jobBuilderFactory;
//
//    @Autowired
//    private StepBuilderFactory stepBuilderFactory;

    @Autowired
    private EntityManagerFactory entityManagerFactory;

//    @Autowired
//    private S3Client s3Client;
    
    @Autowired
    private S3Config s3Service;
    
    @Value("${aws.s3.bucket}")
    private String s3bucketName;

    @Bean
    @StepScope
    public ItemReader<Users> reader() {
        JpaPagingItemReader<Users> reader = new JpaPagingItemReader<>();
        reader.setEntityManagerFactory(entityManagerFactory);
        reader.setQueryString("SELECT e FROM Users e");
        return reader;
    }

    @Bean
    @StepScope
    public FlatFileItemWriter<Users> csvItemwriter() {
        return new FlatFileItemWriterBuilder<Users>()
                .name("csvItemwriter")
                .resource(new FileSystemResource("output.csv"))
                .delimited()
                .names("id", "name")
                .build();
    }
    
//    public ItemProcessor<List<Users>, List<Users>> postgresdbProcessor(){
//    	
//    }

//    @Bean
//    public ItemWriter<Users> s3ItemWriter() {
//        return items -> {
//            String csvFilePath = "output.csv";
////            writeItemsToCsv(items, csvFilePath);
//
////            String s3BucketName = "your-s3-bucket";
//            String s3ObjectKey = "output.csv";
//            s3Service.uploadCSVObject(s3bucketName, s3ObjectKey, new java.io.File(csvFilePath));
//        };
//    }

//    private void writeItemsToCsv(List<? extends Users> items, String filePath) {
//        // Implement logic to write items to a CSV file
//    	
//    }

//    @Bean
//    public Step step(ItemReader<Users> reader, FlatFileItemWriter<Users> writer) {
//        return stepBuilderFactory.get("step")
//                .<Users, Users>chunk(10)
//                .reader(reader)
//                .writer(writer)
//                .build();
//    }
//
//    @Bean
//    public Job job(Step step) {
//        return jobBuilderFactory.get("postgresqlTocsvToS3")
//                .flow(step)
//                .end()
//                .build();
//    }
    

    @Autowired
	private PlatformTransactionManager transactionManager;
    
    @Bean
    public Step exportDBDateToS3AsCSVStep(JobRepository jobRepository) {
    	return new StepBuilder("exportDBDateToS3AsCSVStep", jobRepository)
    			.<Users,Users>chunk(10, transactionManager)
    			.reader(reader())
    			.writer(csvItemwriter())
    			.build();
    }
    
    @Bean
    public Job exportDBDateToS3AsCSV(JobRepository jobRepository) {
    	return new JobBuilder("postgresqlTocsvToS3",jobRepository)
    			.incrementer(new RunIdIncrementer())
    			.start(exportDBDateToS3AsCSVStep(jobRepository))
    			.build();
    }
    
    
    
    
//    @Bean
//	public FlowJobBuilder retrySample(JobRepository jobRepository) {
////		return new JobBuilder("postgresqlTocsvToS3", jobRepository).start(step(jobRepository)).build();
//    	return flowJobBuilder.start(step(reader(),writer())).build();
//	}
    
//    @Bean
//	protected Step step(JobRepository jobRepository) {
//		return new StepBuilder("step", jobRepository).<Users, Object>chunk(1, this.transactionManager)
//			.reader(reader())
//			.writer(writer())
//			.faultTolerant()
//			.retry(Exception.class)
//			.retryLimit(3)
//			.build();
//	}
}
