package com.coderelated.dbTOCSVTOawss3.config;

import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.annotation.AfterJob;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.StepScope;
import org.springframework.batch.core.configuration.support.DefaultBatchConfiguration;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.batch.item.database.JpaPagingItemReader;
import org.springframework.batch.item.file.FlatFileItemWriter;
import org.springframework.batch.item.file.builder.FlatFileItemWriterBuilder;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.FileSystemResource;
import org.springframework.transaction.PlatformTransactionManager;

import com.coderelated.dbTOCSVTOawss3.model.Users;
import com.coderelated.dbTOCSVTOawss3.service.S3Service;

import jakarta.persistence.EntityManagerFactory;

@Configuration
@EnableBatchProcessing
public class BatchConfig extends DefaultBatchConfiguration{

//    @Autowired
//    private JobBuilderFactory jobBuilderFactory;
//
//    @Autowired
//    private StepBuilderFactory stepBuilderFactory;

    @Autowired
    private EntityManagerFactory entityManagerFactory;

    @Autowired
    private S3Service s3Service;
    
    @Value("${aws.s3.bucket}")
    private String s3bucketName;

    @Bean
    @StepScope
    public ItemReader<Users> reader() {
        JpaPagingItemReader<Users> reader = new JpaPagingItemReader<>();
        reader.setEntityManagerFactory(entityManagerFactory);
        reader.setQueryString("SELECT e FROM Users e");
        return reader;
    }

    @Bean
    @StepScope
    public FlatFileItemWriter<Users> csvItemwriter() {
        return new FlatFileItemWriterBuilder<Users>()
                .name("csvItemwriter")
                .resource(new FileSystemResource("output.csv"))
                .delimited()
                .names("id", "name")
                .build();
    }
    
//    public ItemProcessor<List<Users>, List<Users>> postgresdbProcessor(){
//    	
//    }

    @Bean
    public ItemWriter<Users> s3ItemWriter() {
        return items -> {
            String csvFilePath = "output.csv";
//            writeItemsToCsv(items, csvFilePath);

//            String s3BucketName = "your-s3-bucket";
            String s3ObjectKey = "output.csv";
            s3Service.uploadCSVObject(s3bucketName, s3ObjectKey, new java.io.File(csvFilePath));
        };
    }

//    private void writeItemsToCsv(List<? extends Users> items, String filePath) {
//        // Implement logic to write items to a CSV file
//    	
//    }

//    @Bean
//    public Step step(ItemReader<Users> reader, FlatFileItemWriter<Users> writer) {
//        return stepBuilderFactory.get("step")
//                .<Users, Users>chunk(10)
//                .reader(reader)
//                .writer(writer)
//                .build();
//    }
//
//    @Bean
//    public Job job(Step step) {
//        return jobBuilderFactory.get("postgresqlTocsvToS3")
//                .flow(step)
//                .end()
//                .build();
//    }
    

    @Autowired
	private PlatformTransactionManager transactionManager;
    
    @Bean
    public Step exportDBDateToS3AsCSVStep(JobRepository jobRepository) {
    	return new StepBuilder("exportDBDateToS3AsCSVStep", jobRepository)
    			.<Users,Users>chunk(10, transactionManager)
    			.reader(reader())
    			.writer(s3ItemWriter())
    			.build();
    }
    
    @Bean
    public Job exportDBDateToS3AsCSV(JobRepository jobRepository) {
    	return new JobBuilder("postgresqlTocsvToS3Job",jobRepository)
    			.incrementer(new RunIdIncrementer())
    			.start(exportDBDateToS3AsCSVStep(jobRepository))
    			.build();
    }
    
    @AfterJob
    public void afterJob() {
    	System.out.println("job done ..................!");
    }
    
    @Autowired
    private JobOperator operator;
     
    @Autowired
    private JobExplorer jobs;
     
    @Scheduled(fixedRate = 5000)
    public void run() throws Exception {
        List<JobInstance> lastInstances = jobs.getJobInstances(JOB_NAME, 0, 1);
        if (lastInstances.isEmpty()) {
            jobLauncher.run(customerReportJob(), new JobParameters());
        } else {
            operator.startNextInstance(JOB_NAME);
        }
    }
    
    
    
    
//    @Bean
//	public FlowJobBuilder retrySample(JobRepository jobRepository) {
////		return new JobBuilder("postgresqlTocsvToS3", jobRepository).start(step(jobRepository)).build();
//    	return flowJobBuilder.start(step(reader(),writer())).build();
//	}
    
//    @Bean
//	protected Step step(JobRepository jobRepository) {
//		return new StepBuilder("step", jobRepository).<Users, Object>chunk(1, this.transactionManager)
//			.reader(reader())
//			.writer(writer())
//			.faultTolerant()
//			.retry(Exception.class)
//			.retryLimit(3)
//			.build();
//	}
}
